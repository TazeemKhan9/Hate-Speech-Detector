{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hate Speech Streamlit app.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR-dQQg21n2Y",
        "outputId": "70e3c856-24e8-435f-ad53-b6733ab28cf4"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from swachhdata.text import *\n",
        "from keras.utils.data_utils import get_file\n",
        "model= get_file('best_model2.hdf5','https://github.com/TazeemKhan9/Hate-Speech-Detector/blob/main/Model/best_model2.hdf5?raw=true')\n",
        "model = load_model(model)\n",
        "tokenizer =Tokenizer()\n",
        "df=pd.read_csv(\"https://github.com/TazeemKhan9/Hate-Speech-Detector/blob/main/Data/cleaned_tweet.csv?raw=true\")\n",
        "sentiment = ['Hate Speech','Offensive Language','No Issues']\n",
        "PAGE_CONFIG = {\"page_title\":\"Hate Speech Detector\",\"page_icon\":\":smiley:\",\"layout\":\"centered\"}\n",
        "st.set_page_config(**PAGE_CONFIG)\n",
        "\n",
        "def process(tweet):\n",
        "    return TextRecast(tweet, urlRecast = {'process': 'remove'},\n",
        "                      htmlRecast = True,\n",
        "                      EscapeSequenceRecast = True,\n",
        "                      MentionRecast = {'process': 'extract_remove'},\n",
        "                      ContractionsRecast = True,\n",
        "                      CaseRecast = {'process': 'lower'},\n",
        "                      EmojiRecast = {'process': 'remove', 'space_out': False},\n",
        "                      HashtagRecast = {'process': 'remove'},\n",
        "                      StopWordsRecast = {'package': 'nltk', 'stopwords': None},\n",
        "                      NumberRecast = {'process': 'remove', 'seperator': None},\n",
        "                      PunctuationRecast = True,\n",
        "                      LemmatizationRecast = {'package':'nltk'})\n",
        "\n",
        "def main():\n",
        "  menu = [\"Tool\"]\n",
        "  tokenizer =Tokenizer()\n",
        "  choice = st.sidebar.selectbox('Menu',menu)\n",
        "  if choice == 'Tool':\n",
        "    st.header(\"Hate Speech Detector\")\n",
        "    st.write(\"A machine learning tool which can detect if a particular input is hateful or not\")\n",
        "    opt=st.selectbox('Select input format',['Text','Twitter Link','Audio File'])\n",
        "    if opt == 'Text':\n",
        "      user_input = st.text_input('Enter text')\n",
        "    elif opt == 'Twitter Link':\n",
        "      user_input = st.text_input('Enter link')\n",
        "    elif opt == 'Audio File':\n",
        "      user_input = st.file_uploader('Upload File')\n",
        "    if st.button('Generate Text'):\n",
        "      input = process(user_input)\n",
        "      clean=df['tweet'].astype('str')\n",
        "      tokenizer.fit_on_texts(clean.values)\n",
        "      input = tokenizer.texts_to_sequences([input])\n",
        "      test = pad_sequences(input, maxlen=30)\n",
        "      generated_text = sentiment[np.around(model.predict(test), decimals=0).argmax(axis=1)[0]]\n",
        "      st.write(generated_text)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\tmain()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}